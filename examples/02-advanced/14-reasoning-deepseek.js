/**
 * ç¤ºä¾‹ 14: æ·±åº¦æ€è€ƒ (Reasoning / Chain of Thought)
 * 
 * æ ¸å¿ƒä»·å€¼ï¼šæå– AI çš„æ€è€ƒé“¾è·¯ (Extracting the "Why")
 * åƒ DeepSeek-R1 æˆ– OpenAI o1 è¿™æ ·çš„æ¨¡å‹ä¼šè¾“å‡ºæ€è€ƒè¿‡ç¨‹ã€‚
 * Vercel AI SDK v6 æä¾›äº†åŸç”Ÿçš„ `reasoning` å±æ€§ï¼Œ
 * è®©ä½ èƒ½å°†â€œæ€è€ƒè¿‡ç¨‹â€ä¸â€œæœ€ç»ˆå›ç­”â€åˆ†ç¦»ï¼Œä»è€Œåœ¨ UI ä¸Šå®ç°æ›´ä¼˜é›…çš„å±•ç¤ºï¼ˆå¦‚æŠ˜å æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼‰ã€‚
 */

const { generateText } = require('ai');
const { ollama } = require('ai-sdk-ollama');

async function main() {
  console.log('--- ç¤ºä¾‹ 14: æ·±åº¦æ€è€ƒæå– (Reasoning) ---');
  console.log('æç¤ºï¼šæ­¤ç¤ºä¾‹å»ºè®®é…åˆ deepseek-r1 ä½¿ç”¨ä»¥è·å¾—æœ€ä½³æ•ˆæœã€‚');

  try {
    const result = await generateText({
      // å»ºè®®æœ¬åœ°è¿è¡Œ: ollama run deepseek-r1:latest
      model: ollama('deepseek-r1:latest'),
      prompt: 'ä¸ºä»€ä¹ˆå¤©ç©ºæ˜¯è“è‰²çš„ï¼Ÿè¯·å…ˆè¿›è¡Œæ·±åº¦æ€è€ƒï¼Œç„¶åç»™å‡ºç®€çŸ­å›ç­”ã€‚',
    });

    // æ ¸å¿ƒä»·å€¼ï¼šSDK å°è¯•è§£æå¹¶åˆ†ç¦» reasoning æ–‡æœ¬
    const { text, reasoningText } = result;

    if (reasoningText) {
      console.log('\n--- ğŸ§  æ€è€ƒè¿‡ç¨‹ (Reasoning) ---');
      console.log(reasoningText);
    } else {
      console.log('\n(æç¤ºï¼šå½“å‰ç¯å¢ƒæœªè¿”å›ç‹¬ç«‹çš„ reasoningTextï¼Œå¯èƒ½éœ€è¦ SDK æˆ–æ¨¡å‹æä¾›å•†æ”¯æŒ)');
      // å…¼å®¹æ€§å¤„ç†ï¼šå°è¯•ä»æ–‡æœ¬ä¸­æ‰‹åŠ¨æå– <think> æ ‡ç­¾å†…å®¹
      const thinkMatch = text.match(/<think>([\s\S]*?)<\/think>/);
      if (thinkMatch) {
        console.log('\n--- ğŸ§  æ€è€ƒè¿‡ç¨‹ (ä»æ–‡æœ¬ä¸­æå–) ---');
        console.log(thinkMatch[1].trim());
      }
    }

    // ç§»é™¤æ–‡æœ¬ä¸­çš„ <think> éƒ¨åˆ†ä»¥è·å¾—çº¯å‡€çš„å›ç­”
    const cleanText = text.replace(/<think>[\s\S]*?<\/think>/, '').trim();

    console.log('\n--- âœ¨ æœ€ç»ˆå›ç­” ---');
    console.log(cleanText);

  } catch (error) {
    console.error('\næ‰§è¡Œå¤±è´¥:', error.message);
    console.log('æç¤º: è¯·ç¡®ä¿å·²å®‰è£…å¹¶å¯åŠ¨äº† deepseek-r1 æ¨¡å‹: ollama run deepseek-r1');
  }
}

main().catch(console.error);
