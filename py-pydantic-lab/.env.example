# --- LLM Provider Configuration ---
# Options: deepseek, openai, ollama, azure_ad, gemini_vertex, or custom
LLM_PROVIDER=deepseek

# --- Google Vertex AI Configuration ---
GOOGLE_PROJECT_ID=your_gcp_project_id_here
GOOGLE_LOCATION=us-central1
GOOGLE_MODEL_NAME=gemini-1.5-pro

# --- DeepSeek Configuration ---
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# --- OpenAI Configuration ---
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL_NAME=gpt-4o

# --- Ollama Configuration (Local) ---
OLLAMA_MODEL_NAME=llama3
OLLAMA_BASE_URL=http://localhost:11434/v1

# --- Custom/Generic OpenAI-Compatible Configuration ---
# LLM_BASE_URL=https://api.yourprovider.com/v1
# LLM_API_KEY=your_api_key
# LLM_MODEL_NAME=your-model-name

# --- Observability ---
# LOGFIRE_TOKEN=your_logfire_token_here

# --- Corporate Network / Proxy Configuration (Optional) ---
# If you are behind a corporate firewall, uncomment and set the proxy URL
# LLM_PROXY_URL=http://your-proxy-server:port
